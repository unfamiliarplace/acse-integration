{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/unfamiliarplace/acse-integration/blob/main/data_science/data_science_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Funfamiliarplace%2Facse-integration&branch=main&subPath=data_science%2Fdata_science_3.ipynb&depth=2\"  target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three data science notebooks\n",
    "\n",
    "Here's what we've covered and will cover in this series:\n",
    "\n",
    "Part 1: We examined Python's core data structures and saw some simple visualizations.\n",
    "\n",
    "Part 2: We will explore and learn to use Python's dedicated data science tools in more depth.\n",
    "\n",
    "**Part 3: We will apply our knowledge to a project with multiple steps and visualizations.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of this notebook\n",
    "\n",
    "The goal of this notebook is use Python's dedicated data science tools for a specific purpose related to data science.\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "**1. Finding and cleaning data:** Locating, downloading, and cleaning data for use.\n",
    "\n",
    "**2. Analyzing and visualizing data:** Transforming, calculating statistics, and presenting the results of data.\n",
    "\n",
    "**Conclusion**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For both students and ourselves, an important question whenever we learn something is: \"Why are we learning this? What can I use it for?\" We've seen the basics of how to use the tools. As an English teacher I know likes to write in the margins of essays: \"So what?\"\n",
    "\n",
    "It's a challenging question, but the beautiful thing about this stage is that you can open it to students. If they've been prepared well, then the applications should be limitless. In data science, that means you should be able to ask a lot of different real-world questions and get interesting answers.\n",
    "\n",
    "However, it's not always possible to come up with an interesting question from thin air. Often, the best questions actually arise from seeing something curious or encountering some underexplained data or hearing an anecdote and wondering whether it's typical or exceptional.\n",
    "\n",
    "So let's go hunting!\n",
    "\n",
    "### Learning goals\n",
    "\n",
    "* A1. demonstrate the ability to use different data types, including one-dimensional arrays, in computer programs.\n",
    "\n",
    "* D2.2 demonstrate an understanding of an area of collaborative research between computer science and another field.\n",
    "\n",
    "### Success criteria\n",
    "\n",
    "* I can choose and implement a structure to represent a dataset in code.\n",
    "\n",
    "* I can manipulate a data structure in code to select, organize, and analyze data.\n",
    "\n",
    "* I can create a suitable visualization of a dataset in code in order to better understand a question.\n",
    "\n",
    "> [Source: Ontario Curriculum (2008)](https://www.edu.gov.on.ca/eng/curriculum/secondary/computer10to12_2008.pdf#page=41)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding and cleaning data\n",
    "\n",
    "Where shall we begin looking for data? There are many paid and a few good free sources of significant datasets. Helping students comb through these is itself a great learning opportunity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data sources\n",
    "\n",
    "* [data.world](https://data.world): Large collection of datasets. Requires sign-up.\n",
    "\n",
    "* [LODE Databases](https://www.statcan.gc.ca/en/lode/databases): A Canadian gov't initiative to create open municipal, provincial, and federal datasets.\n",
    "\n",
    "* [Statistics Canada](https://www150.statcan.gc.ca/n1/en/type/data): Large collection of datasets on all things measurable in Canada (economy, geography, society, etc.)\n",
    "\n",
    "* [data.gov](https://data.census.gov/): The US Census Bureau's equivalent of StatsCan.\n",
    "\n",
    "* [World Bank](https://data.worldbank.org/): A global version of the same. Can also zoom into the country level.\n",
    "\n",
    "* [First Nations Information Governance Centre](https://fnigc.ca/): A Canadian First Nations initiative to create [Indigenous data sovereignty](https://guides.library.utoronto.ca/indigenousstudies/datasovereignty).\n",
    "\n",
    "* [World Health Organization](https://www.who.int/data/gho/): Global health-related data.\n",
    "\n",
    "* [Open Data Sciences Conference](https://odsc.com/): They don't directly link to data science sources, but they promote resources, e.g. [this Medium.com list of free natural language processing datasets](https://odsc.medium.com/20-open-datasets-for-natural-language-processing-538fbfaf8e38).\n",
    "\n",
    "* [PEW Research](https://www.webfx.com/blog/marketing/data-sources/): Survey-based data. Requires sign-up.\n",
    "\n",
    "* [AWS Datasets](https://registry.opendata.aws/): Useful, but a little harder to access because they require either AWS integration, the AWS CLI, or following the links the original authors' repositories.\n",
    "\n",
    "* [Many more](https://www.webfx.com/blog/marketing/data-sources/) ...\n",
    "\n",
    "### Narrowing down an interest\n",
    "\n",
    "1. **Choosing my data source:** As a Canadian with general interests, I'm going to start at StatsCan. One thing to keep in mind with them is that they have both public and private datasets. Many of the public ones are just snapshots from a single census, and the resulting table is easy to understand but not very deeply informative. However, they do have some datasets with longitudinal aspects, so I'll look for one of those that's more worthwhile throwing programmatic data science at.\n",
    "\n",
    "2. **Exploring data sets:** There are a lot of subjects on StatsCan: agriculture and food, business, children, construction, crime, digital society, economy, education, energy, families, health, and more. Seeing a list like this is wonderful since these are exactly the sort of prompts students need to lead their curiosity. In my case, I'll click on agriculture and food. It has a lot of datasets and an obvious interest. :)\n",
    "<br><br>\n",
    "This brings me to a set of about 650 items, of which almost 600 are data tables. I'll limit myself to those since those are the easiest way to ingest data such that we can work with it in code.\n",
    "<br><br>\n",
    "That's a lot of tables to wade through, so I'll use the subcategory filter to limit it to food (130 tables). One of the top ones is \"Food available in Canada\" (in kilos per person per year). This sound vaguely interesting. Another one is \"Supply and disposition of food in Canada\", which sounds to me like how it was used, and thus a bit richer. I'll use that.\n",
    "\n",
    "<img width=\"600\" src=\"assets/screenshots/sc_002.png\" />\n",
    "\n",
    "3. **Preliminary skim:** As we saw in the last notebook, it's possible to preview datasets in Python using `pandas`, but since we want to get a sense of what's out there without having to download all these tables, I'll just skim through it in the browser.\n",
    "<br><br>\n",
    "I click on \"Supply and disposition of food in Canada\". On StatsCan, you can choose various filters for the table views. Here I can choose one of many commodities, and I can choose a reference period. Wonder of wonders, the reference period lets me go back all the way to 1960! This is a jackpot dataset â€” lots to analyze. I can see that the resulting tables give me supply (broken down into stock, production, imports) vs. disposition (domestic disappearance, exports, manufacturing, and waste). I think this dataset will be worth poking around.\n",
    "\n",
    "<img width=\"600\" src=\"assets/screenshots/sc_001.png\" />\n",
    "\n",
    "### Downloading the data\n",
    "\n",
    "On StatsCan, when you click on `Download Options`, you get quite a range. I'm going to choose the option to download the entire table as a CSV. That gives us the most flexibility to work with it in code.\n",
    "\n",
    "<img width=\"600\" src=\"assets/screenshots/sc_003.png\" />\n",
    "\n",
    "### Cleaning the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing and visualizing data\n",
    "\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "458dd1d06817a72759ca62d766d5a1c58019d69edba750c2eb07d80bb7630974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
